Traceback (most recent call last):
  File "train_da.py", line 837, in <module>
    train(config)
  File "train_da.py", line 233, in train
    model, optimizer, lr_scheduler = pretrain(model, optimizer, sources[0], original_target_name, lr_scheduler, epochs=config['pre_train'], log=True, writer=writer)
  File "train_da.py", line 108, in pretrain
    meta_train=False, mark=0)
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 161, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 171, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/userhome/root/workspace/chengyl/ours_barlow_rep_clef_copy/models/daml_c.py", line 321, in forward
    logits, feat_src = self._inner_forward(src_trn_data, OrderedDict(self.named_parameters()), 0)
  File "/userhome/root/workspace/chengyl/ours_barlow_rep_clef_copy/models/daml_c.py", line 101, in _inner_forward
    feat = self.encoder(x, get_child_dict(params, 'encoder'), episode)
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/userhome/root/workspace/chengyl/ours_barlow_rep_clef_copy/models/encoders/resnet50.py", line 186, in forward
    out = layer(out, get_child_dict(params, str(i)), episode)
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/userhome/root/workspace/chengyl/ours_barlow_rep_clef_copy/models/encoders/resnet50.py", line 87, in forward
    out3 = self.conv3(out3, get_child_dict(params, 'conv3'))
  File "/root/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/userhome/root/workspace/chengyl/ours_barlow_rep_clef_copy/models/modules.py", line 82, in forward
    x = F.conv2d(x, weight, bias, self.stride, self.padding)
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 10.76 GiB total capacity; 520.97 MiB already allocated; 78.44 MiB free; 582.00 MiB reserved in total by PyTorch)

